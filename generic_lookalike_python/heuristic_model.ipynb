{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERIZED VARIABLES\n",
    "\n",
    "PROJECT_ID = \"{{PROJECT_ID}}\"\n",
    "TARGET_BUCKET = \"{{TARGET_BUCKET}}\"\n",
    "ORGANIZATION_ID = \"{{ORGANIZATION_ID}}\"\n",
    "DATAFOUNDATION_TABLE = \"{{DATAFOUNDATION_TABLE}}\"\n",
    "BUCKET_PIPELINE = \"{{BUCKET_PIPELINE}}\"\n",
    "FEATURE_LIST = {{FEATURE_LIST}}\n",
    "AUDIENCE_ID = {{AUDIENCE_ID}}\n",
    "TOPIC_ID = \"{{TOPIC_ID}}\"\n",
    "MAX_MSISDN_COUNT = {{MAX_MSISDN_COUNT}}\n",
    "MSISDN_SAMPLE_PATH = \"{{MSISDN_SAMPLE_PATH}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARAMETERIZED VARIABLES\n",
    "\n",
    "# PROJECT_ID = \"sbox-ext-collab-prd-50f1\"\n",
    "# TARGET_BUCKET = \"gs://model-results-lookalike-model-sandbox\"\n",
    "# ORGANIZATION_ID = \"CUSTOMER_A\"\n",
    "# # DATAFOUNDATION_TABLE = \"owned_summary.df_customer_data_profile\"\n",
    "# DATAFOUNDATION_TABLE = \"owned_summary.test_heuristic_lookalike\"\n",
    "# BUCKET_PIPELINE = \"gs://bucket-collab-prd/Arifian/vertex_pipeline_files\"\n",
    "# FEATURE_LIST = ['age','tenure','total_arpu','data_usage_in_mb','data_usage_duration','total_topups',\n",
    "#             'number_of_topups_1m','total_topups_1m','total_usage_GB_1m','daily_GB_consumption_rate_1m','number_of_topups_2m',\n",
    "#              'total_topups_2m','total_usage_GB_2m','daily_GB_consumption_rate_2m','number_of_topups_3m','total_topups_3m','total_usage_GB_3m',\n",
    "#              'daily_GB_consumption_rate_3m']\n",
    "# AUDIENCE_ID = 1\n",
    "# TOPIC_ID = \"tempbucket-to-audience-table\"\n",
    "# MAX_MSISDN_COUNT = 100\n",
    "# MSISDN_SAMPLE_LIST = ['Yia/XQuEu4dKaKi3jf29xbZsqsRV0XCHw9QkYR1gk8k=']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_GCS_LOCATION = TARGET_BUCKET+\"/\"+ORGANIZATION_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'generic_lookalike_python_'+ORGANIZATION_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "REGION = \"asia-southeast2\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "PIPELINE_ROOT = f\"{BUCKET_PIPELINE}/pipeline_root/heuristic_model_python_{ORGANIZATION_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "\n",
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_PIPELINE, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "tmpdir = tempfile.gettempdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get msisdn sample list\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=[\n",
    "        \"pandas==1.5.2\", \"gcsfs==2022.11.0\", \"pyarrow==10.0.1\"\n",
    "    ],\n",
    "    output_component_file=tmpdir+\"/get_msisdns_seed.yaml\"\n",
    ")\n",
    "def get_msisdns_seed(\n",
    "    msisdn_sample_path: str, project_id: str\n",
    ") -> NamedTuple('Outputs', [('msisdn_sample', list)]):\n",
    "    import pandas as pd\n",
    "    import gcsfs\n",
    "\n",
    "    df = pd.read_csv(msisdn_sample_path)\n",
    "    msisdn_list = df['msisdn'].values.tolist()\n",
    "\n",
    "    from typing import NamedTuple\n",
    "    outputs = NamedTuple('Outputs', [('msisdn_sample', list)])\n",
    "    return outputs(msisdn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script heuristic lookalike\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=[\n",
    "        \"pandas==1.3.5\", \"google-cloud-bigquery==2.34.4\", \"pyarrow==10.0.0\",\n",
    "        \"numpy==1.21.6\", \n",
    "        \"scikit-learn==1.0.2\",\n",
    "        \"scipy==1.7.3\",\n",
    "    ],\n",
    "    output_component_file=tmpdir+\"/heuristic_script_python.yaml\"\n",
    ")\n",
    "def heuristic_script_python(\n",
    "    lookalike_result: Output[Dataset], table_full_name: str,\n",
    "    project_id: str, feature_list: list, msisdn_sample_list: list,\n",
    "    max_msisdn_count: int\n",
    "):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.spatial import distance\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    pd.set_option('display.max_columns', 300)\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "    from google.cloud import bigquery\n",
    "    client = bigquery.Client(project_id)\n",
    "\n",
    "    feature_list_str = ', '.join(feature_list)\n",
    "    \n",
    "    sql = f\"\"\"SELECT \n",
    "    msisdn, {feature_list_str}\n",
    "FROM `{table_full_name}`\n",
    "WHERE (partition_month = '2022-10-01')\"\"\"\n",
    "    df = client.query(sql).to_dataframe()\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df_sub_seed = df[df['msisdn'].isin(msisdn_sample_list)]\n",
    "    df_sub_seed = df_sub_seed.loc[:, df_sub_seed.columns != 'msisdn']\n",
    "\n",
    "    df_pop_msisdn = df[~(df['msisdn'].isin(msisdn_sample_list))]    \n",
    "    df_sub_pop = df_pop_msisdn.loc[:, df_pop_msisdn.columns != 'msisdn']\n",
    "    df_pop_msisdn = df_pop_msisdn[['msisdn']]\n",
    "\n",
    "    del df\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "    df_sub_seed = df_sub_seed.reset_index(drop=True)\n",
    "\n",
    "    distance_matrix = pd.DataFrame(columns=['Distance'])\n",
    "    for i in range(df_sub_pop.shape[0]):\n",
    "        df_sub_pop_temp = df_sub_pop.head(0)\n",
    "        df_sub_pop_temp.loc[i] = df_sub_pop.iloc[i]\n",
    "        distance = euclidean_distances(df_sub_seed, df_sub_pop_temp)\n",
    "        distance_matrix.loc[i] = min(distance)\n",
    "    distance_matrix\n",
    "\n",
    "    df_pop_msisdn = df_pop_msisdn.reset_index(drop=True)\n",
    "    df_population_dist_agg = pd.concat([df_pop_msisdn, distance_matrix], axis=1)\n",
    "    df_population_dist_agg = df_population_dist_agg.sort_values('Distance', ascending=False)\n",
    "    \n",
    "    df_population_dist_agg = df_population_dist_agg[['msisdn']][0:max_msisdn_count]\n",
    "\n",
    "    df_population_dist_agg.to_parquet(lookalike_result.path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to gcs\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=[\n",
    "        \"pandas==1.5.2\", \"gcsfs==2022.11.0\", \"pyarrow==10.0.1\", \"datetime\"\n",
    "    ],\n",
    "    output_component_file=tmpdir+\"/write_to_gcs.yaml\"\n",
    ")\n",
    "def write_to_gcs(\n",
    "    data: Input[Dataset], project_id: str, \n",
    "    audience_id: int, bucket: str\n",
    ") -> NamedTuple('Outputs', [('data_gcs_path', str)]):\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    df_to_store = pd.read_parquet(data.path)\n",
    "    df_to_store['audience_id'] = audience_id\n",
    "    df_to_store = df_to_store[['audience_id', 'msisdn']]\n",
    "\n",
    "    path = bucket+f\"/generic_python_model_{TIMESTAMP}.csv\"\n",
    "\n",
    "    df_to_store.to_csv(path, index=False, header=False)\n",
    "    from typing import NamedTuple\n",
    "    \n",
    "    outputs = NamedTuple('Outputs', [('data_gcs_path', str)])\n",
    "    return outputs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish to pubsub\n",
    "\n",
    "@component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-pubsub==2.13.4\", \"datetime\"\n",
    "    ],\n",
    "    output_component_file=tmpdir+\"/aud_data_to_pubsub.yaml\"\n",
    ")\n",
    "\n",
    "def aud_data_to_pubsub(\n",
    "    data_gcs_path: str, topic_id: str,\n",
    "    project_id: str, audience_id: int\n",
    "):\n",
    "    import json\n",
    "    from google.cloud import pubsub_v1\n",
    "    publisher = pubsub_v1.PublisherClient()\n",
    "    topic_path = publisher.topic_path(project_id, topic_id)\n",
    "\n",
    "    message = {\n",
    "        'audience_id': audience_id,\n",
    "        'file_path': data_gcs_path,\n",
    "    }\n",
    "\n",
    "    future = publisher.publish(topic_path, json.dumps(message).encode(\"utf-8\"))\n",
    "    print(future.result())\n",
    "    print(f\"Published messages to {topic_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.v1.custom_job import create_custom_training_job_from_component\n",
    "\n",
    "heuristic_script_python_v2 = create_custom_training_job_from_component(\n",
    "    heuristic_script_python,\n",
    "    display_name = 'heuristic_script_python',\n",
    "    machine_type = 'n1-highmem-16',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=pipeline_name.replace(\"_\",\"-\").lower(),\n",
    ")\n",
    "def pipeline(\n",
    "    target_bucket: str,\n",
    "    datafoundation_table_fullname: str,\n",
    "    project_id: str,\n",
    "    feature_list: list,\n",
    "    msisdn_sample_path: str,\n",
    "    max_msisdn_count: int,\n",
    "    audience_id: int,\n",
    "    topic_id: str\n",
    "):\n",
    "    get_lookalike_msisdn_seed = get_msisdns_seed(\n",
    "        msisdn_sample_path=msisdn_sample_path, project_id=project_id\n",
    "    )\n",
    "    heuristic_lookalike = heuristic_script_python_v2(\n",
    "        table_full_name=datafoundation_table_fullname,\n",
    "        project_id=project_id, feature_list=feature_list,\n",
    "        msisdn_sample_list=get_lookalike_msisdn_seed.outputs['msisdn_sample'], max_msisdn_count=max_msisdn_count,\n",
    "        project=project_id,\n",
    "        location=REGION\n",
    "    )    \n",
    "    write_result_to_gcs = write_to_gcs(\n",
    "        data=heuristic_lookalike.outputs[\"lookalike_result\"],\n",
    "        bucket=target_bucket, project_id=project_id,\n",
    "        audience_id=audience_id\n",
    "    )\n",
    "    trigger_load_gcs_to_cloudsql = aud_data_to_pubsub(\n",
    "        data_gcs_path=write_result_to_gcs.outputs['data_gcs_path'],\n",
    "        topic_id=topic_id, project_id=project_id, \n",
    "        audience_id=audience_id\n",
    "    )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananda.dwi/Documents/indosat/poc_vertex/env/lib/python3.9/site-packages/kfp/v2/compiler/compiler.py:1290: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=tmpdir+f\"/{pipeline_name}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/asia-southeast2/pipelines/runs/generic-lookalike-python-customer-a-20221221082715?project=731696491468\n",
      "PipelineJob projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/731696491468/locations/asia-southeast2/pipelineJobs/generic-lookalike-python-customer-a-20221221082715\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_NAME = pipeline_name + \"_\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=tmpdir+f\"/{pipeline_name}.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        \"project_id\": PROJECT_ID,\n",
    "        \"datafoundation_table_fullname\": DATAFOUNDATION_TABLE,\n",
    "        \"feature_list\": FEATURE_LIST,\n",
    "        \"target_bucket\": TARGET_GCS_LOCATION,\n",
    "        \"audience_id\": AUDIENCE_ID,\n",
    "        \"msisdn_sample_path\": MSISDN_SAMPLE_PATH,\n",
    "        \"max_msisdn_count\": MAX_MSISDN_COUNT,\n",
    "        \"audience_id\": AUDIENCE_ID,\n",
    "        \"topic_id\": TOPIC_ID\n",
    "    },\n",
    "    enable_caching=False\n",
    ")\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18ab93e5cae76da871c8ec2ed964d533dd2ee52f4436e759813a11e0df5d2609"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
